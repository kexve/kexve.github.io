---
layout: post 
title: FedScale论文阅读    
categories:  PaperRead   
---   

## FedScale: Benchmarking Model and System Performance of Federated Learning at Scale 一个FL基准，以实现全面和标准化的FL评估
![20211206171149](https://cdn.jsdelivr.net/gh/kexve/img/img/20211206171149.png)

### 联邦学习中的问题
1. 系统效率：减少计算负荷（较小的模型）或通信流量（本地SGD）
2. 统计效率：设计数据异构性感知算法（客户端聚类），以更少的训练轮获得更好的训练精度
3. 隐私和安全：可靠的策略（差分隐私），更加隐私保护和强大的潜在攻击

### 评估FL解决方案必须调查以下情况
1. 这些基准大多是从传统的ML基准(例如MLPerf)借鉴来的，或者是为模拟FL环境设计的，比如TensorFlow Federated或PySyft。  
2. 其次，现有的基准测试常常忽略了系统速度、连接性和客户端的可用性(例如，FedML和Flower)。这阻碍了FL考虑系统效率的努力，并导致了过于乐观的统计性能。
3. 他们的数据集是小规模的，主要是因为他们的实验环境无法模拟大规模FL部署。

### 贡献
1. 整合了最全面的FL数据集来评估实际FL部署的不同方面。FedScale目前拥有18个真实的FL数据集，跨越小、中、大尺度，用于各种各样的任务类别，如图像分类、目标检测、语言建模、语音识别、机器翻译、推荐和强化学习。
2. 建立了一个自动评估平台，FedScale自动运行时(FAR)，在一个更现实的环境中简化和标准化FL评估。FAR集成了真实的FL统计数据和系统数据集，因此可以精确地确定当今工作中需要的各种实际FL度量。FAR允许使用灵活的api轻松部署新插件
3. 在FedScale设置中的FL工作进行了深入的基准测试实验，并强调了在异构感知方式下协同优化系统和统计效率的迫切需要，特别是在解决系统掉线和偏倚模型性能方面。

## 核心内容FAR
FAR是一个自动化评估平台，它可以模拟GPU/CPU上的实际FL行为，同时提供各种实用的FL指标，如计算/通信成本、延迟和挂钟时间，用于评估当前的工作。如图7所示，FAR主要由三个部分组成:  
1. 聚合器模拟器：一旦接收到新的事件，事件监视器将激活处理程序(例如，执行模型聚合的聚合处理程序)或通信器来发送/接收消息。通信器记录每个网络流量的大小(成本)及其FL运行时延迟(traffic_size/client_bandwidth)。
2. 客户端模拟器：
3. 资源管理器:它协调可用的物理资源进行评估，以最大限度地利用资源。例如，当该轮的参与者数量超过了资源容量(例如，在几个图形处理器上模拟数千个客户端)，资源管理器将客户端超额分配的任务排队，一旦资源可用，就从这个队列调度一个新的客户端模拟请求。

----- 2021-12-07 更新 -----

FAR为插件提供了灵活的api，可以适应不同的执行后端(例如PyTorch和TensorFlow)，让开发者可以快速部署新的插件进行定制的评估。

FAR可以通过内置api包含新的实际数据集(统计客户端或系统行为)。例如，开发人员可以通过利用API (load_client_availability)导入自己的客户端可用性数据集，FAR将在评估期间自动强制执行此跟踪。我们在附录中提供了更多的示例，包括与其他框架的比较，以展示如何在FAR中轻松地评估当今不同的FL算法。

FAR是可扩展和高效的，FAR可以在独立(单个CPU/GPU)和分布式(多个CPU/GPU)设置下执行大规模模拟(例如，每轮数千名参与者)。这是因为:(1)FAR可以支持单个GPU上的多处理，这样多个客户端模拟器可以在同一GPU上共存;(2)我们的资源管理器监控机器的细粒度资源利用率，将过度提交的模拟请求排队，(3)FAR通过重叠不同客户端的通信和计算阶段，实现资源利用率最大化。

