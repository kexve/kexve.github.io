---
layout: post
title: transformer相关
categories: 深度学习
---

## attention和self attention
Attention函数的本质可以被描述为一个查询（query）到一系列（键key-值value）对的映射。  
![20220919150558](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220919150558.png)

