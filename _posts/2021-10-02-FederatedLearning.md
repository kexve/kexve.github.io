---
layout: post    
title: 联邦学习    

categories:  Knowledge   
---    

## 联邦学习概念 federated learning  

与joint learning联合学习不同, 它是指将不同来源的数据整合在一起用于*多任务建模训练*的场景中.  
与multitask learning多任务学习不同, 它是指*迁移学习*的一个子方向, 旨在有多个学习目标并部分公用数据的情况下, 尽量利用共有模型提高学习效果.   

## 联邦学习是如何保护隐私和数据安全的？

### 模型训练

在模型训练阶段，模型相关的信息可以在各方之间交换，但数据不能交换，因此各个站点上的数据将受到保护.  

### 模型推理

在模型推理阶段，训练好的联邦学习模型可以置于联邦学习系统的各参与方，也可以供多方共享。这是联邦学习的具体过程，也就是它的定义.

## 联邦学习的4种基本类型

横向联邦学习、纵向联邦学习、联邦迁移学习和联邦强化学习.

## 联邦学习的发展动机

1. 用户隐私和数据安全方面的需求
2. 为了最大化地利用云系统下终端设备的计算能力, 减少了通过原始数据与中央服务器通信的需要

## 人工智能面临的挑战

这些系统的训练都需要很大的数据量才能达到一个令人满意的性能水平, 我们能够获得的通常都是“小数据”，即这些数据要么规模较小，要么缺少标签或者部分特征数值等重要信息, 我们不得不面对难以桥接的数据孤岛.  
数据拥有者只允许这些数据保存在自己手中，进而会形成各自孤立的数据孤岛.   
人工智能产业面临数据困境的另一个原因是，各方协同分享处理大数据的益处并不明显, 整合带来的性能增益是如何在参与方中分配的也不能完全确定. 

## 联邦学习的挑战

参与方（例如，智能手机）和中央聚合服务器之间的通信链接可能是慢速并且不稳定的，来自不同参与方的数据可能会导致出现非独立同分布的情况，并且不同的参与方可能有数量不均的训练数据样本，这可能导致联邦模型产生偏差，甚至会使联邦模型训练失败。难以被认证身份，这使得联邦学习模型容易遭到恶意攻击。

## 联邦学习的主要着眼

提升安全性以及处理统计学上的难题

## 联邦学习的开源平台

1. Federated AI Technology Enabler（FATE）,微众银行人工智能项目组发起的一个开源项目
2. TensorFlow Federated（TFF）,联邦学习和其他计算方法在去中心化数据集上进行实验的开源框架
3. 等等等

## 面向隐私保护的机器学习系统（Privacy-Preserving Machine Learning，PPML）

机器学习中的三种主要攻击类型：

1. 完整性（Integrity）：出现检测错误，例如可能会将入侵点检测为正常（假阴性）。
2. 可用性（Availability）：出现分类错误（假阴性和假阳性），即系统会变成不可用的。这是比完整性攻击更宽泛的一种攻击类型。
3. 机密性（Confidentiality）：敏感信息（如训练数据或训练模型）会出现泄露。

## 隐私威胁模型

攻击可能的发生阶段：

1. 数据发布：特征推理攻击（Attribute-Inference Attacks）
2. 模型训练：重构攻击（Reconstruction Attacks）,重构数据提供者的原始数据，或者学习关于数据的更多信息.**重构攻击是联邦学习的主要隐私关注点**
3. 模型推理：向工程技术来获取模型的额外信息，以此实施模型反演攻击（Model Inversion Attacks）或成员推理攻击（Membership-Inference Attacks）

### 重构攻击

敌手的目标是在模型的训练期间抽取训练数据，或抽取训练数据的特征向量。

在联邦学习中，只将模型的权重更新和梯度信息与其他参与方共享，如果数据结构是已知的，梯度信息可能也会被利用，从而泄露关于训练数据的额外信息。应当避免使用存储显式特征值的机器学习模型，例如支持向量机（SVM）和k近邻（kNN）模型。

安全多方计算和同态加密可以被用来通过保护计算中间结果来抵御重构攻击。

**计算方只应当被授予对模型的黑盒访问权限。**

### 模型反演攻击

敌手的目的是从模型中抽取训练数据或训练数据的特征向量。

理论上，对于一个*N*维的线性模型，一个敌手可以通过*N*+1次查询来窃取整个模型的内容。该问题的形式化是从（x，hθ（x））中求解θ。

为了抵御模型反演攻击，应当向敌手暴露尽可能少的关于模型的信息。对模型的访问应当被限制为黑盒访问，模型输出同样应当受限。

**将预测的类别标签作为返回结果等；同态加密的贝叶斯神经网络**

### 成员推理攻击

敌手的目标是判断模型的训练集中是否包含特定的样本。敌手的目标是获知给定样本是否在模型的训练集中。

### 特征推理攻击

敌手出于恶意目的，将数据去匿名化或锁定记录的拥有者。在面对能够获取其他背景知识的强大敌手时，匿名化将会失效。

**可能的解决方法----群组匿名化隐私方法。**

## 攻击者和安全模型

现有研究工作设计两种类型的敌手：

1. 半诚实的（Semi-honest）敌手，遵守协议，但也会试图从接收到的信息中学习更多除输出以外的信息。
2. 恶意的（Malicious）敌手，不遵守协议，可以执行任意的攻击行为。

大多数的PPML研究都考虑了半诚实的敌手模型。主要原因是，在联邦学习中，诚实地遵守协议是对各方都有利的。另一个原因是，在密码学中，首先建立一个针对半诚实的敌手的安全协议是一种标准的方法，然后可以**通过零知识证明（zero-knowledge proof）对其进行加强，进而防御恶意的敌手的攻击**。



## 隐私保护技术

### 安全多方计算（SMPC，Secure Multi-Party Computation）

在安全多方计算中，目的是协同地从每一方的隐私输入中计算函数的结果，而不用将这些输入展示给其他方。

证明安全多方计算协议是安全的标准方法为仿真范式（simulation paradigm）。

安全多方计算能够通过三种不同的框架来实现：**秘密共享被广泛认为是安全多方计算的核心**

#### 不经意传输（Oblivious Transfer，OT）

Alice 拥有秘密 SA ，Bob 拥有秘密 SB 。Alice 和 Bob 想要交换秘密，要求两方都有可能得到秘密并且秘密拥有方不知道对方是否得到秘密。

#### 秘密共享（Secret Sharing，SS）



#### 阈值同态加密（Threshold Homomorphic Encryption，THE）



### 同态加密



### 差分隐私



