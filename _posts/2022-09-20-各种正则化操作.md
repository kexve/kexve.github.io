---
layout: post
title: 各类正则化操作
categories: 深度学习
extMath: true
---

## dropout

模型融合的操作如下：将多个模型的预测结果取平均。如果 model 很复杂时，这一招是往往有用的，能够有效的降低模型的 variance。
![20220928111324](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111324.png)
而 dropout 就相当于每个 mini batch 训练一个模型，虽然每次更新只更新一个网络的参数，由于每个子网络之间参数共享，对每个子网络的训练相当于对整个网络的训练，所以最终得到了针对整个数据集的多个模型。
![20220928111407](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111407.png)
那么在 testing 的时候，按照 ensemble 方法，我们需要把之前的每个不同 dropout 的 network 拿出来，然后把 train data 丢到 network 里面去，每一个 network 都会给你一个结果，这些结果的平均值就是最终的结果。但是实际上没有办法这样做，因为 network 太多了。（每个神经元有 2 种可能，一共 N 个神经元，则有个网络）。dropout 最神奇的是：当你把一个完整的 network 不进行 dropout，但是将它的 weights 乘以（1-p）%，然后将 train data 输入，得到的 output y：之前做 average 的结果跟 output y 是 approximated。
![20220928111440](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111440.png)
针对只有 2 个神经元的全连接网络，dropout 后一个产生四种可能的网络结构，对他们的输出做 average，等效于不做 dropout 时对每个 w\*(1-p)%，所以 dropout 的本质就是模型融合。同时只有是 linear network，ensemble 才会等于 weights multiply 一个值。所以一般都是在全连接网络后面加入 dropout。
![20220928111638](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111638.png)
实践中比较常用的不是直接 dropout，而是 inverted dropout。原理是在训练的时候 dropout 之后做一个比例缩放，将所有 w 乘 1/(1-p),则测试的时候不需要做缩放。无论做不做 dropout，可保持 inference 代码不变。

```python
"""
反向随机失活: 推荐实现方式.
在训练的时候drop和调整数值范围，测试时不做任何事.
"""
p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = (np.random.rand(*H1.shape) < p) / p # 第一个随机失活遮罩. 注意/p!
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = (np.random.rand(*H2.shape) < p) / p # 第二个随机失活遮罩. 注意/p!
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3

  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)

def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) # 不用数值范围调整了
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  out = np.dot(W3, H2) + b3
```

## L1 正则化和 L2 正则化

L1 正则和 L2 正则是为了防止模型过拟合，添加在损失函数后面，构成对模型复杂的惩罚项。

结构风险 = 经验风险+惩罚项（正则化）

### Lasso 回归，L1 正则

#### 带约束条件的优化分解(拉格朗日乘子法)

令目标函数为：

$$min_w J(w;X,y)$$

为了降低模型的复杂度，减少模型的参数个数，我们可以通过为目标函数增加约束条件，得

$$
min_w J(w;X,y) \\
s.t. ||w||_0 <= C
$$

$ \left \Vert w \right \Vert \_0 $ 表示 L0 范数，表示的是向量 w 中非零元素的个数，让非零元素的个数小于某一个 C，就能有效的控制模型中的非零元素的个数。它是一个有约束优化问题，而且是 NP hard 问题，因此对它进行“松弛”。即不再严格要求 w 中的某些元素为 0，而是使他尽可能的接近 0，所以这里使用 L1 L2 范数来代替 L0 范数，即：

$$
min_w J(w;X,y) \\
s.t. ||w||_1 <= C
$$

利用拉格朗日乘子法求解：

$$L(w,\alpha)=J(w;X,y)+\alpha(||w||_1 - C)$$

其中，$\alpha$是拉格朗日系数，$\alpha >0$，假设$\alpha$的最优解为$\alpha^*$，对拉格朗日函数求最小化等价于：

$$L(w,\alpha)=J(w;X,y)+\alpha^*||w||_1$$

#### 贝叶斯学派：最大后验概率

似然函数  
**无监督模型**

假设观测到的数据样本点为 X1,X2,...Xn，它们都是独立同分布的，服从概率分布 P(X)，那么似然函数为

$$L=\prod_{i=1}^{N}P(X_i)$$

假设概率分布 P(x)的参数$\theta$未知，那么可以通过最大化似然函数来估计参数$\theta$，即

$$\theta=argmax_\theta L(\theta)=argmax_\theta \prod_{i=1}^{N}P(X_i)$$

对应的对数似然函数为：

$$\theta=argmax_\theta \sum_{i=1}^{N}logP_\theta(X_i)$$

等式右边乘以 1/N，相当于计算$logP_\theta(X_i)$关于训练数据经验分布$\hat P_{data}$的期望：

$$\theta=argmax_\theta \sum_{i=1}^{N} \frac{1}{N}logP_\theta(X_i)=argmax_\theta E_{\hat P _{data}}[logP_\theta(X)]$$

**有监督模型**

对于判别模型来说，我们通常要学习的是 P(Y\|X)而不是 P(X,Y)，它对应的条件最大似然函数是：

$$\theta=argmax_\theta P_\theta(Y|X)$$

假设样本是独立同分布的，所以

$$
\theta=argmax_\theta \sum_{X,Y}^{} P_\theta(Y|X) \\
=argmax_\theta \sum_{i=1}^{N}logP_\theta(y_i|x_i)
$$

_假设条件概率分布 P(Y\|X)服从高斯分布_，即：

$$P_\theta(y_i|x_i) \sim N(\theta^T x_i, \sigma^2)$$

代到前面，对应的条件似然函数可写成：

$$
l(\theta)=\sum_{i=1}^{N}logP_\theta(y_i|x_i) \\
=\sum_{i=1}^{N}log[\frac{1}{\sqrt{2 \pi} \sigma} exp(-\frac{(y_i-\theta^T x_i)^2}{2 \sigma^2})] \\
=-\frac{1}{2\sigma^2} \sum_{i=1}^{m}(y_i-\theta^T x_i)^2+C
$$

目标函数为负的对数似然函数，即：

$$L(\theta;X,y) = \frac{1}{2\sigma^2} \sum_{i=1}^{m}(y_i-\theta^T x_i)^2$$

在最大后验概率估计中，我们将参数$\theta$看作随机变量，参数$\theta$的概率分布为：

$$P(\theta | X,y) = \frac{P(\theta,X,y)}{P(X,y)} = \frac{P(X,y|\theta) P(\theta)}{P(X,y)} \propto P(y|X,\theta) P(\theta)$$

同样取对数

$$MAP=log[P(y|X,\theta) P(\theta)]=logP(y|X,\theta)+logP(\theta)$$

可以看到，**后验概率分布为似然函数加上 logP(θ)，P(θ)的意义是对参数 θ 的概率分布的先验假设。** 在收集到训练样本(X,y)后，则可根据 θ 在(X,y)下的后验概率对 θ 进行修正，从而做出对 θ 更好的估计。

**L2 正则化**

假设$\theta_j$的先验分布服从均值为 0 的高斯分布，即

$$\theta_j \sim N(0,\sigma^2)$$

则有：

$$logP(\theta)=log \prod_{j} P(\theta_j) = -\frac{1}{2\sigma^2} \sum_j \theta^2_j + C$$

可以看到，在高斯分布下，logP(θ) 相当于在目标函数中增加 L2 正则项。$-\frac{1}{2\sigma^2}$为正则化系数。

**L1 正则化**

假设 θj 服从均值为 0，参数为 a 的拉普拉斯分布，即:

$$P(\theta_j)=\frac{1}{\sqrt{2a}} exp(\frac{-|\theta_j|}{a}) $$

则有：

$$logP(\theta) = -\frac{1}{a} \sum_j |\theta_j|+C$$

可以看到，在拉普拉斯分布下 log P(θ)的效果等价于在目标函数中增加 L1 正则项。$\frac{1}{a}$为正则化系数。

L1 正则化可通过假设权重 θ 的先验分布为拉普拉斯分布，由最大后验概率估计导出。

L2 正则化可通过假设权重 θ 的先验分布为高斯分布，由最大后验概率估计导出。

### Ridge 回归，L2 正则

### 求解方法

**_带 L1 正则的损失函数并不是处处可导，因此不可采用梯度下降法求导，可采用坐标轴下降法求导；
带 L2 正则的损失函数处处可导，因此可采用梯度下降法求导。_**

L1 正则采用回归系数的绝对值之和，这样会将回归系数限定在一个正方形内，正方形的顶点在坐标轴上，回归系数的限定区域与训练集误差的区域的交点处，求得使损失函数达到最小的值；L1 正则往往在坐标轴上取得最优解，这样就会使得一些特征的系数为 0，选择的特征数量比较少，产生稀疏权重矩阵。
  L2 正则采用回归系数的平方和，这样会将回归系数限定在一个圆内，回归系数的限定区域与训练集的误差区域的交点往往靠近坐标轴，但不在坐标轴上，这就导致了 L2 正则选择的特征数量比较多，但是有一些特征的系数比较小。

![20220929145908](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220929145908.png)

### 坐标轴下降法和梯度下降法

坐标轴下降法

![20220929150206](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220929150206.png)

梯度下降法

### 几个问题

1. 为什么参数越小代表模型越简单？  
   越是复杂的模型，越是尝试对所有样本进行拟合，包括异常点。这就会造成在较小的区间中产生较大的波动，这个较大的波动也会反映在这个区间的导数比较大。
   只有越大的参数才可能产生较大的导数。因此参数越小，导数相对越小，模型就越简单。
2. 实现参数的稀疏有什么好处？  
   因为参数的稀疏，在一定程度上实现了特征的选择。一般而言，大部分特征对模型是没有贡献的。这些没有用的特征虽然可以减少训练集上的误差，但是对测试集的样本，反而会产生干扰。稀疏参数的引入，可以将那些无用的特征的权重为 0.
