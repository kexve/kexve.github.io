---
layout: post
title: 各类正则化操作
categories: 深度学习
extMath: true
---

## dropout
模型融合的操作如下：将多个模型的预测结果取平均。如果model很复杂时，这一招是往往有用的，能够有效的降低模型的variance。
![20220928111324](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111324.png)
而dropout就相当于每个mini batch 训练一个模型，虽然每次更新只更新一个网络的参数，由于每个子网络之间参数共享，对每个子网络的训练相当于对整个网络的训练，所以最终得到了针对整个数据集的多个模型。
![20220928111407](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111407.png)
那么在testing的时候，按照ensemble方法，我们需要把之前的每个不同dropout的network拿出来，然后把train data丢到network里面去，每一个network都会给你一个结果，这些结果的平均值就是最终的结果。但是实际上没有办法这样做，因为network太多了。（每个神经元有2种可能，一共N个神经元，则有个网络）。dropout最神奇的是：当你把一个完整的network不进行dropout，但是将它的weights乘以（1-p）%，然后将train data输入，得到的output y：之前做average的结果跟output y是approximated。
![20220928111440](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111440.png)
针对只有2个神经元的全连接网络，dropout后一个产生四种可能的网络结构，对他们的输出做average，等效于不做dropout时对每个w*(1-p)%，所以dropout的本质就是模型融合。同时只有是linear network，ensemble才会等于weights multiply一个值。所以一般都是在全连接网络后面加入dropout。
![20220928111638](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220928111638.png)
实践中比较常用的不是直接dropout，而是inverted dropout。原理是在训练的时候dropout之后做一个比例缩放，将所有w乘1/(1-p),则测试的时候不需要做缩放。无论做不做dropout，可保持inference代码不变。

``` python
"""
反向随机失活: 推荐实现方式.
在训练的时候drop和调整数值范围，测试时不做任何事.
"""
p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = (np.random.rand(*H1.shape) < p) / p # 第一个随机失活遮罩. 注意/p!
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = (np.random.rand(*H2.shape) < p) / p # 第二个随机失活遮罩. 注意/p!
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3

  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)

def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) # 不用数值范围调整了
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  out = np.dot(W3, H2) + b3
```

## L1正则化和L2正则化
L1正则和L2正则是为了防止模型过拟合，添加在损失函数后面，构成对模型复杂的惩罚项。

结构风险 = 经验风险+惩罚项（正则化）

### Lasso回归，L1正则
#### 1.带约束条件的优化分解(拉格朗日乘子法)
令目标函数为：
$$min_w J(w;X,y)$$
为了降低模型的复杂度，减少模型的参数个数，我们可以通过为目标函数增加约束条件，得
$$min_w J(w;X,y) \\
s.t. ||w||_0 <= C$$
$||w||_0$表示L0范数，表示的是向量w中非零元素的个数，让非零元素的个数小于某一个C，就能有效的控制模型中的非零元素的个数。它是一个有约束优化问题，而且是NP hard问题，因此对它进行“松弛”。即不再严格要求w中的某些元素为0，而是使他尽可能的接近0，所以这里使用L1 L2范数来代替L0范数，即：
$$min_w J(w;X,y) \\
s.t. ||w||_1 <= C$$
利用拉格朗日乘子法求解：
$$L(w,\alpha)=J(w;X,y)+\alpha(||w||_1 - C)$$
其中，$\alpha$是拉格朗日系数，$\alpha >0$，假设$\alpha$的最优解为$\alpha^*$，对拉格朗日函数求最小化等价于：
$$L(w,\alpha)=J(w;X,y)+\alpha^*||w||_1$$

#### 2.贝叶斯学派：最大后验概率

似然函数  
**无监督模型**

假设观测到的数据样本点为X1,X2,...Xn，它们都是独立同分布的，服从概率分布P(X)，那么似然函数为
$$L=\prod_{i=1}^{N}P(X_i)$$
假设概率分布P(x)的参数$\theta$未知，那么可以通过最大化似然函数来估计参数$\theta$，即
$$\theta=argmax_\theta L(\theta)=argmax_\theta \prod_{i=1}^{N}P(X_i)$$
对应的对数似然函数为：
$$\theta=argmax_\theta \sum_{i=1}^{N}logP_\theta(X_i)$$
等式右边乘以1/N，相当于计算$logP_\theta(X_i)$关于训练数据经验分布$\hat P _{data}$的期望：
$$\theta=argmax_\theta \sum_{i=1}^{N} \frac{1}{N}logP_\theta(X_i)=argmax_\theta E_{\hat P _{data}}[logP_\theta(X)]$$

**有监督模型**

对于判别模型来说，我们通常要学习的是P(Y|X)而不是P(X,Y)，它对应的条件最大似然函数是：
$$\theta=argmax_\theta P_\theta(Y|X)$$
假设样本是独立同分布的，所以
$$\theta=argmax_\theta \sum_{X,Y}^{} P_\theta(Y|X) \\
=argmax_\theta \sum_{i=1}^{N}logP_\theta(y_i|x_i)$$
*假设条件概率分布P(Y|X)服从高斯分布*，即：
$$P_\theta(y_i|x_i) \sim N(\theta^T x_i, \sigma^2)$$
代到前面，对应的条件似然函数可写成：
$$l(\theta)=\sum_{i=1}^{N}logP_\theta(y_i|x_i) \\
=\sum_{i=1}^{N}log[\frac{1}{\sqrt{2 \pi} \sigma} exp(-\frac{(y_i-\theta^T x_i)^2}{2 \sigma^2})] \\
=-\frac{1}{2\sigma^2} \sum_{i=1}^{m}(y_i-\theta^T x_i)^2+C
$$
目标函数为负的对数似然函数，即：
$$L(\theta;X,y) = \frac{1}{2\sigma^2} \sum_{i=1}^{m}(y_i-\theta^T x_i)^2$$
在最大后验概率估计中，我们将参数$\theta$看作随机变量，参数$\theta$的概率分布为：
$$P(\theta | X,y) = \frac{P(\theta,X,y)}{P(X,y)} = \frac{P(X,y|\theta) P(\theta)}{P(X,y)} \propto P(y|X,\theta) P(\theta)$$
同样取对数
$$MAP=log[P(y|X,\theta) P(\theta)]=logP(y|X,\theta)+logP(\theta)$$
可以看到，**后验概率分布为似然函数加上logP(θ)，P(θ)的意义是对参数θ的概率分布的先验假设。** 在收集到训练样本(X,y)后，则可根据θ在(X,y)下的后验概率对θ进行修正，从而做出对θ更好的估计。

**L2正则化**

假设$\theta_j$的先验分布服从均值为0的高斯分布，即
$$\theta_j \sim N(0,\sigma^2)$$
则有：
$$logP(\theta)=log \prod_{j} P(\theta_j) = -\frac{1}{2\sigma^2} \sum_j \theta^2_j + C$$
可以看到，在高斯分布下，logP(θ) 相当于在目标函数中增加L2正则项。$-\frac{1}{2\sigma^2}$为正则化系数。

**L1正则化**

假设θj服从均值为0，参数为a的拉普拉斯分布，即:
$$P(\theta_j)=\frac{1}{\sqrt{2a}} exp(\frac{-|\theta_j|}{a}) $$
则有：
$$logP(\theta) = -\frac{1}{a} \sum_j |\theta_j|+C$$
可以看到，在拉普拉斯分布下log P(θ)的效果等价于在目标函数中增加L1正则项。$\frac{1}{a}$为正则化系数。

L1正则化可通过假设权重θ的先验分布为拉普拉斯分布，由最大后验概率估计导出。

L2正则化可通过假设权重θ的先验分布为高斯分布，由最大后验概率估计导出。

### Ridge回归，L2正则

### 求解方法
***带L1正则的损失函数并不是处处可导，因此不可采用梯度下降法求导，可采用坐标轴下降法求导；
带L2正则的损失函数处处可导，因此可采用梯度下降法求导。***

L1正则采用回归系数的绝对值之和，这样会将回归系数限定在一个正方形内，正方形的顶点在坐标轴上，回归系数的限定区域与训练集误差的区域的交点处，求得使损失函数达到最小的值；L1正则往往在坐标轴上取得最优解，这样就会使得一些特征的系数为0，选择的特征数量比较少，产生稀疏权重矩阵。
  L2正则采用回归系数的平方和，这样会将回归系数限定在一个圆内，回归系数的限定区域与训练集的误差区域的交点往往靠近坐标轴，但不在坐标轴上，这就导致了L2正则选择的特征数量比较多，但是有一些特征的系数比较小。

![20220929145908](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220929145908.png)

### 坐标轴下降法和梯度下降法
坐标轴下降法

![20220929150206](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220929150206.png)

梯度下降法

### 几个问题

1. 为什么参数越小代表模型越简单？  
越是复杂的模型，越是尝试对所有样本进行拟合，包括异常点。这就会造成在较小的区间中产生较大的波动，这个较大的波动也会反映在这个区间的导数比较大。
只有越大的参数才可能产生较大的导数。因此参数越小，导数相对越小，模型就越简单。  
2. 实现参数的稀疏有什么好处？  
因为参数的稀疏，在一定程度上实现了特征的选择。一般而言，大部分特征对模型是没有贡献的。这些没有用的特征虽然可以减少训练集上的误差，但是对测试集的样本，反而会产生干扰。稀疏参数的引入，可以将那些无用的特征的权重为0.
