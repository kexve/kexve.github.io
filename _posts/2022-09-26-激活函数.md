---
layout: post
title: 激活函数
categories: 深度学习
---

## 常见的激活函数

![20220926184930](https://cdn.jsdelivr.net/gh/kexve/img@main/image_blog20220926184930.png)

## 选择最佳的激活函数

也就是说，根据定义，激活函数有如下特性。

1. 激活函数是非线性的。在没有激活函数的情况下，重复应用(w\*x+b)会导致相同线性形式
   （仿射线性）的函数。非线性使得整个网络能够逼近更复杂的函数。
2. 激活函数是可微的，因此可以通过它们计算梯度。正如我们在 Hardtanh 或 ReLU 中所看
   到的，点不连续性是很好的。

没有这些特性，网络要么退回到线性模型，要么变得难以训练。

以下是函数的真实情况。

1. 它们至少有一个敏感范围，在这个范围内，对输入的变化会导致输出产生相应的变化，
   这是训练所需要的。
2. 它们包含许多不敏感（或饱和）的范围，即输入的变化导致输出的变化很小或没有变化。
   举例来说，通过结合不同权重和输入偏置的敏感范围，可以很容易地使用 Hardtanh 对一个
   函数进行分段线性逼近。

通常情况下（但并非普遍如此），激活函数至少有以下一种特征。

1. 当输入到负无穷大时，接近（或满足）一个下限。
2. 正无穷时相似但上界相反。

想想反向传播的工作过程，我们可以发现当输入在响应范围内时，错误会通过激活函数更有效
地向后传播，而不会对输入饱和的神经元产生很大影响（由于输出周围的平坦区域，梯度将接近于 0）。

综合起来，所有这些组成了一个非常强大的机制：在一个由线性+激活单元构成的网络中，
当不同的输入呈现给网络时，不同的单元会对相同的输入在不同范围内响应；与这些输入相关的
错误将主要影响在敏感区域工作的神经元，使其他单元不受学习过程的影响。此外，由于在敏感
范围内，激活对其输入的导数通常接近于 1，因此通过梯度下降估计在该范围内运行的单元的线
性变换参数将与我们之前看到的线性拟合非常相似。
我们开始对如何并行地加入许多线性+激活单元并将它们一个接一个地叠加，从而得到一个能
够近似复杂函数的数学对象有了更深的理解。不同的单元组合会对不同范围的输入进行响应，这些
单元的参数相对容易通过梯度下降来优化，因为在输出饱和之前，学习将表现得很像线性函数。

在某种程度上，
我们放弃解释，以换取解决日益复杂的问题的可能性。换句话说，我们有时缺乏能力、信息或计算
资源来为我们所呈现的事物建立一个明确的模型，所以数据驱动是我们前进的唯一途径。
